a <- ggplot(data=data, aes(x=Sex, y=Amount)) + geom_bar(stat="identity",fill = "red") + ggtitle("Disabilities by Sex") + xlab('Sex') + ylab('Amount')
a
R.home()
Sys.getenv("R_HOME")
R.home()
R.home()
install.packages("tm")
download.file("http://cran.cnr.berkeley.edu/src/contrib/Archive/Rstem/Rstem_0.4-1.tar.gz", "Rstem_0.4-1.tar.gz")
install.packages("Rstem_0.4-1.tar.gz", repos=NULL, type="source")
# authorisation
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, ROAuth, RCurl)
api_key = 'wfaNU49sQeFBjfPgY7kkoMI2I'
api_secret = 'DqZBzaLn9Wc1XeZzVgPTR7gRLF2y5tevU7M4sX0UeJCKerjlH9'
access_token = '786160713173651456-rCkuWeIvgKf21urXHcacFRxojzGXkrW'
access_token_secret = 'IxntCD69XiBxJXa3XFO9bij6plezqtTjN7VxNpF3L7TEP'
# Set SSL certs globally
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
# set up the URLs
reqURL = 'https://api.twitter.com/oauth/request_token'
accessURL = 'https://api.twitter.com/oauth/access_token'
authURL = 'https://api.twitter.com/oauth/authorize'
twitCred = OAuthFactory$new(consumerKey = api_key, consumerSecret = api_secret, requestURL = reqURL, accessURL = accessURL, authURL = authURL)
twitCred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl'))
if (!require('pacman')) install.packages('pacman&')
pacman::p_load(devtools, installr)
install.Rtools()
install_url('http://cran.r-project.org/src/contrib/Archive/Rstem/Rstem_0.4-1.tar.gz')
install_url('http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz')
# START HERE
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, sentiment, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, base64enc)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'wfaNU49sQeFBjfPgY7kkoMI2I'
api_secret = 'DqZBzaLn9Wc1XeZzVgPTR7gRLF2y5tevU7M4sX0UeJCKerjlH9'
access_token = '786160713173651456-rCkuWeIvgKf21urXHcacFRxojzGXkrW'
access_token_secret = 'IxntCD69XiBxJXa3XFO9bij6plezqtTjN7VxNpF3L7TEP'
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
# harvest some tweets
game_tweets = searchTwitter('Call of Duty: Infinite Warfare', n=10000, lang='en')
# get the text
game_txt = sapply(game_tweets, function(x) x$getText())
# remove retweet entities
game_txt = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', game_txt)
# remove at people
game_txt = gsub('@\\w+', '', game_txt)
# remove punctuation
game_txt = gsub('[[:punct:]]', '', game_txt)
# remove numbers
game_txt = gsub('[[:digit:]]', '', game_txt)
# remove html links
game_txt = gsub('http\\w+', '', game_txt)
# remove unnecessary spaces
game_txt = gsub('[ \t]{2,}', '', game_txt)
game_txt = gsub('^\\s+|\\s+$', '', game_txt)
# define 'tolower error handling' function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, 'error'))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
game_txt = sapply(game_txt, try.error)
# remove NAs in game_txt
game_txt = game_txt[!is.na(game_txt)]
names(game_txt) = NULL
game_txt <- game_txt[ ! duplicated( game_txt ) ]
# Perform Sentiment Analysis
# classify emotion
class_emo = classify_emotion(game_txt, algorithm='bayes', prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# substitute NA's by 'unknown'
emotion[is.na(emotion)] = 'unknown'
# classify polarity
class_pol = classify_polarity(game_txt, algorithm='bayes')
# get polarity best fit
polarity = class_pol[,4]
# Create data frame with the results and obtain some general statistics
# data frame with results
sent_df = data.frame(text=game_txt, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
write.csv(sent_df, file = "GameTweets.csv")
# Let’s do some plots of the obtained results
# plot distribution of emotions
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette='Dark2') +
labs(x='emotion categories', y='number of tweets') +
ggtitle('Sentiment Analysis of Tweets about Call of Duty: Infinite Warfare\n(classification by emotion)') +
theme(plot.title = element_text(size=12, face='bold'))
# plot distribution of polarity
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette='RdGy') +
labs(x='polarity categories', y='number of tweets') +
ggtitle('Sentiment Analysis of Tweets about Call of Duty: Infinite Warfare\n(classification by polarity)') +
theme(plot.title = element_text(size=12, face='bold'))
write.csv(sent_df, file = "gameTweets.csv")
# Separate the text by emotions and visualize the words with a comparison cloud
# separating text by emotion
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep('', nemo)
for (i in 1:nemo)
{
tmp = game_txt[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse='')
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
# comparison word cloud
col=brewer.pal(6,"Dark2")
wordcloud(tdm, min.freq=25, scale=c(5,2),rot.per = 0.25,
random.color=T, max.word=45, random.order=F,colors=col)
download.file("http://cran.cnr.berkeley.edu/src/contrib/Archive/Rstem/Rstem_0.4-1.tar.gz", "Rstem_0.4-1.tar.gz")
install.packages("Rstem_0.4-1.tar.gz", repos=NULL, type="source")
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, ROAuth, RCurl)
api_key = 'wfaNU49sQeFBjfPgY7kkoMI2I'
api_secret = 'DqZBzaLn9Wc1XeZzVgPTR7gRLF2y5tevU7M4sX0UeJCKerjlH9'
access_token = '786160713173651456-rCkuWeIvgKf21urXHcacFRxojzGXkrW'
access_token_secret = 'IxntCD69XiBxJXa3XFO9bij6plezqtTjN7VxNpF3L7TEP'
# Set SSL certs globally
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
# set up the URLs
reqURL = 'https://api.twitter.com/oauth/request_token'
accessURL = 'https://api.twitter.com/oauth/access_token'
authURL = 'https://api.twitter.com/oauth/authorize'
twitCred = OAuthFactory$new(consumerKey = api_key, consumerSecret = api_secret, requestURL = reqURL, accessURL = accessURL, authURL = authURL)
twitCred$handshake(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl'))
if (!require('pacman')) install.packages('pacman&')
pacman::p_load(devtools, installr)
pacman::p_load(devtools, install)
if (!require('pacman')) install.packages('pacman&')
pacman::p_load(devtools, installr)
install.Rtools()
install_url('http://cran.r-project.org/src/contrib/Archive/Rstem/Rstem_0.4-1.tar.gz')
install_url('http://cran.r-project.org/src/contrib/Archive/sentiment/sentiment_0.2.tar.gz')
if (!require('pacman')) install.packages('pacman')
pacman::p_load(twitteR, sentiment, plyr, ggplot2, wordcloud, RColorBrewer, httpuv, RCurl, base64enc)
options(RCurlOptions = list(cainfo = system.file('CurlSSL', 'cacert.pem', package = 'RCurl')))
api_key = 'wfaNU49sQeFBjfPgY7kkoMI2I'
api_secret = 'DqZBzaLn9Wc1XeZzVgPTR7gRLF2y5tevU7M4sX0UeJCKerjlH9'
access_token = '786160713173651456-rCkuWeIvgKf21urXHcacFRxojzGXkrW'
access_token_secret = 'IxntCD69XiBxJXa3XFO9bij6plezqtTjN7VxNpF3L7TEP'
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
game_tweets = searchTwitter('Call of Duty: Infinite Warfare', n=10000, lang='en')
game_tweets = searchTwitter('Call of Duty', n=10000, lang='en')
game_txt = sapply(game_tweets, function(x) x$getText())
# remove retweet entities
game_txt = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', game_txt)
# remove at people
game_txt = gsub('@\\w+', '', game_txt)
# remove punctuation
game_txt = gsub('[[:punct:]]', '', game_txt)
# remove numbers
game_txt = gsub('[[:digit:]]', '', game_txt)
# remove html links
game_txt = gsub('http\\w+', '', game_txt)
# remove unnecessary spaces
game_txt = gsub('[ \t]{2,}', '', game_txt)
game_txt = gsub('^\\s+|\\s+$', '', game_txt)
# define 'tolower error handling' function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, 'error'))
y = tolower(x)
# result
return(y)
}
# lower case using try.error with sapply
game_txt = sapply(game_txt, try.error)
# remove NAs in game_txt
game_txt = game_txt[!is.na(game_txt)]
names(game_txt) = NULL
game_txt <- game_txt[ ! duplicated( game_txt ) ]
# Perform Sentiment Analysis
# classify emotion
class_emo = classify_emotion(game_txt, algorithm='bayes', prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# substitute NA's by 'unknown'
emotion[is.na(emotion)] = 'unknown'
# classify polarity
class_pol = classify_polarity(game_txt, algorithm='bayes')
# get polarity best fit
polarity = class_pol[,4]
# Create data frame with the results and obtain some general statistics
# data frame with results
sent_df = data.frame(text=game_txt, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
write.csv(sent_df, file = "GameTweets.csv")
# Let’s do some plots of the obtained results
# plot distribution of emotions
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette='Dark2') +
labs(x='emotion categories', y='number of tweets') +
ggtitle('Sentiment Analysis of Tweets about Call of Duty: Infinite Warfare\n(classification by emotion)') +
theme(plot.title = element_text(size=12, face='bold'))
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette='RdGy') +
labs(x='polarity categories', y='number of tweets') +
ggtitle('Sentiment Analysis of Tweets about Call of Duty: Infinite Warfare\n(classification by polarity)') +
theme(plot.title = element_text(size=12, face='bold'))
write.csv(sent_df, file = "gameTweets.csv")
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep('', nemo)
for (i in 1:nemo)
{
tmp = game_txt[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse='')
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
# comparison word cloud
col=brewer.pal(6,"Dark2")
wordcloud(tdm, min.freq=25, scale=c(5,2),rot.per = 0.25,
random.color=T, max.word=45, random.order=F,colors=col)
install.packages("tm")
install.packages("tm")
emo.docs = removeWords(emo.docs, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
# comparison word cloud
col=brewer.pal(6,"Dark2")
wordcloud(tdm, min.freq=25, scale=c(5,2),rot.per = 0.25,
random.color=T, max.word=45, random.order=F,colors=col)
TermDocumentMatrix(Corpus(VectorSource(dat[, 1])),
control = list(
removePunctuation = TRUE,
stopwords = TRUE
)
)
TermDocumentMatrix(Corpus(VectorSource(corpus)),
control = list(
removePunctuation = TRUE,
stopwords = TRUE
)
)
col=brewer.pal(6,"Dark2")
wordcloud(tdm, min.freq=25, scale=c(5,2),rot.per = 0.25,
random.color=T, max.word=45, random.order=F,colors=col)
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep('', nemo)
for (i in 1:nemo)
{
tmp = game_txt[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse='')
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
# comparison word cloud
col=brewer.pal(6,"Dark2")
wordcloud(tdm, min.freq=25, scale=c(5,2),rot.per = 0.25,
random.color=T, max.word=45, random.order=F,colors=col)
library(tm)
emo.docs = removeWords(emo.docs, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
# comparison word cloud
col=brewer.pal(6,"Dark2")
wordcloud(tdm, min.freq=25, scale=c(5,2),rot.per = 0.25,
random.color=T, max.word=45, random.order=F,colors=col)
game_tweets = searchTwitter('Infinite Warfare', n=10000, lang='en')
# get the text
game_txt = sapply(game_tweets, function(x) x$getText())
# remove retweet entities
game_txt = gsub('(RT|via)((?:\\b\\W*@\\w+)+)', '', game_txt)
# remove at people
game_txt = gsub('@\\w+', '', game_txt)
# remove punctuation
game_txt = gsub('[[:punct:]]', '', game_txt)
# remove numbers
game_txt = gsub('[[:digit:]]', '', game_txt)
# remove html links
game_txt = gsub('http\\w+', '', game_txt)
# remove unnecessary spaces
game_txt = gsub('[ \t]{2,}', '', game_txt)
game_txt = gsub('^\\s+|\\s+$', '', game_txt)
# define 'tolower error handling' function
try.error = function(x)
{
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, 'error'))
y = tolower(x)
return(y)
# result
}
# lower case using try.error with sapply
game_txt = sapply(game_txt, try.error)
# remove NAs in game_txt
game_txt = game_txt[!is.na(game_txt)]
names(game_txt) = NULL
game_txt <- game_txt[ ! duplicated( game_txt ) ]
# Perform Sentiment Analysis
# classify emotion
class_emo = classify_emotion(game_txt, algorithm='bayes', prior=1.0)
# get emotion best fit
emotion = class_emo[,7]
# substitute NA's by 'unknown'
emotion[is.na(emotion)] = 'unknown'
# classify polarity
class_pol = classify_polarity(game_txt, algorithm='bayes')
# get polarity best fit
polarity = class_pol[,4]
# Create data frame with the results and obtain some general statistics
# data frame with results
sent_df = data.frame(text=game_txt, emotion=emotion,
polarity=polarity, stringsAsFactors=FALSE)
# sort data frame
sent_df = within(sent_df,
emotion <- factor(emotion, levels=names(sort(table(emotion), decreasing=TRUE))))
write.csv(sent_df, file = "GameTweets.csv")
# Let’s do some plots of the obtained results
# plot distribution of emotions
ggplot(sent_df, aes(x=emotion)) +
geom_bar(aes(y=..count.., fill=emotion)) +
scale_fill_brewer(palette='Dark2') +
labs(x='emotion categories', y='number of tweets') +
ggtitle('Sentiment Analysis of Tweets about Call of Duty: Infinite Warfare\n(classification by emotion)') +
theme(plot.title = element_text(size=12, face='bold'))
ggplot(sent_df, aes(x=polarity)) +
geom_bar(aes(y=..count.., fill=polarity)) +
scale_fill_brewer(palette='RdGy') +
labs(x='polarity categories', y='number of tweets') +
ggtitle('Sentiment Analysis of Tweets about Call of Duty: Infinite Warfare\n(classification by polarity)') +
theme(plot.title = element_text(size=12, face='bold'))
write.csv(sent_df, file = "gameTweets.csv")
# Separate the text by emotions and visualize the words with a comparison cloud
# separating text by emotion
emos = levels(factor(sent_df$emotion))
nemo = length(emos)
emo.docs = rep('', nemo)
for (i in 1:nemo)
{
tmp = game_txt[emotion == emos[i]]
emo.docs[i] = paste(tmp, collapse='')
}
# remove stopwords
emo.docs = removeWords(emo.docs, stopwords('english'))
# create corpus
corpus = Corpus(VectorSource(emo.docs))
tdm = TermDocumentMatrix(corpus)
# comparison word cloud
col=brewer.pal(6,"Dark2")
wordcloud(tdm, min.freq=25, scale=c(5,2),rot.per = 0.25,
random.color=T, max.word=45, random.order=F,colors=col)
r java()
rjava()
rjava()
system.file("jri", package="rJava")
System.out.println(System.getProperty("java.library.path"));
export R_HOME=/usr/lib64/R
export R_HOME=/usr/lib64/R
R.home()
export CLASSPATH=.:/usr/lib/R/site-library/rJava/jri/
usr@srv $ export R_HOME=/usr/lib64/R
usr@srv $ netbeans
system.file("jri", package="rJava")
install.packages("rJava")
install.packages("rJava")
install.packages("rServe")
install.packages("Rserve")
library(Rserve)
Rserve()
Rserve('--no-save')
install.packages(Rserve)
install.packages("Rserve")
libaray("Rserve")
library("Rserve")
Rserve()
Rserve(args="--no-save")
quit()
library("Rserve")
Rserve(args="--no-save")
install.packages("HistogramTools")
library(HistogramTools)
deathCounts <- c(565, 116, 69, 78, 319, 501, 633, 655, 848, 1226, 1633, 2459, 3375, 4669, 6152, 7436, 9526, 12619, 12455, 7113, 2104, 241)
ageBreaks <- c(0, 1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 110)
myhist <- PreBinnedHistogram(
breaks = ageBreaks,
counts = deathCounts,
xname = "Age at Death of Australian Males, 2012")
plot(myhist)
plot(myhist, col="red")
setwd("/Users/declanbarnes/Documents/FinalYearProject/DataSets/")
library(HistogramTools)
library(RMySQL)
library(DBI)
library(stats)
library(C50)
library(ggmap)
library(ggplot2)
library(gmodels)
library(googleVis)
library(knitr)
library(plotly)
library(tidyr)
library(caret)
library(dplyr)
library(lattice)
library(plyr)
library(rworldmap)
library(grid)
centres <- read.csv("healthcentres.csv", header=TRUE)
leinster <- subset(centres, County =="Wicklow" | County =="Wexford" | County =="Dublin" | County =="Kildare"
| County =="Meath" | County =="Carlow" | County =="Kilkenny"
| County =="Laois" | County =="Offaly" | County =="Westmeath"
| County =="Longford" | County =="Louth")
currentCentres <- get_map(location = c(lon = mean(leinster$long_xcord), lat = mean(leinster$lat_ycord)), zoom = 8,
source="google",maptype="roadmap",crop=FALSE)
ggmap(currentCentres)
map <- ggmap(currentCentres, legend = "none")+geom_point(aes(x = leinster$long_xcord, y = leinster$lat_ycord),
data = leinster, alpha = .7, color = "red", size = 1)
print(map)
setwd("/Users/declanbarnes/Documents/FinalYearProject/DataSets/")
library(HistogramTools)
library(RMySQL)
library(DBI)
library(stats)
library(C50)
library(ggmap)
library(ggplot2)
library(gmodels)
library(googleVis)
library(knitr)
library(plotly)
library(tidyr)
library(caret)
library(dplyr)
library(lattice)
library(plyr)
library(rworldmap)
library(grid)
centres <- read.csv("healthcentres.csv", header=TRUE)
leinster <- subset(centres, County =="Wicklow" | County =="Wexford" | County =="Dublin" | County =="Kildare"
| County =="Meath" | County =="Carlow" | County =="Kilkenny"
| County =="Laois" | County =="Offaly" | County =="Westmeath"
| County =="Longford" | County =="Louth")
data = data.frame(
ID = as.numeric(leinster$ID),
longitude = as.numeric(leinster$long_xcord),
latitude = as.numeric(leinster$lat_ycord)
)
make_circles <- function(centers, radius, nPoints = 100){
# centers: the data frame of centers with ID
# radius: radius measured in kilometer
#
meanLat <- mean(centers$latitude)
# length per longitude changes with lattitude, so need correction
radiusLon <- radius /111 / cos(meanLat/57.3)
radiusLat <- radius / 111
circleDF <- data.frame(ID = rep(centers$ID, each = nPoints))
angle <- seq(0,2*pi,length.out = nPoints)
circleDF$lon <- unlist(lapply(centers$longitude, function(x) x + radiusLon * cos(angle)))
circleDF$lat <- unlist(lapply(centers$latitude, function(x) x + radiusLat * sin(angle)))
return(circleDF)
}
myCircles <- make_circles(data, 0.1)
island <- get_map(location = c(lon = mean(leinster$long_xcord), lat = mean(leinster$lat_ycord)), zoom = 8,
source="google",maptype="roadmap")
islandMap <- ggmap(island)
RL = geom_point(aes(x = longitude, y = latitude), data = data, color = "#ff0000")
islandMap + RL +
scale_x_continuous(limits = c(-8.5, -5), expand = c(0, 0)) +
scale_y_continuous(limits = c(52.1, 54.2), expand = c(0, 0)) +
########### add circles
geom_point(aes(x = lon, y = lat, group = ID), data = myCircles, size = 10, shape = 1,  color = "darkblue")
install.packages("plotly")
install.packages("plotly")
library(plotly)
p <- plot_ly(islandMap)
d <- data.frame(islandMap)
q()
